## 使用说明

### Step 1: 查找预训练模型
打开tensorflow hub https://tfhub.dev/
输入想要使用的模型

### Step 2: 下载模型
带有google的域名，内陆地区一般是无法直接访问的
这里下载bert文本分类模型
https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed
或者NNLM模型（word2vec）
https://tfhub.dev/google/nnlm-en-dim128/1?tf-hub-format=compress

### Step 3:  解压模型
模型解压到脚本所在目录，**不要修改**目录名 
